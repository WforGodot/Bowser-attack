{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'screenshots/screenshot_1700386515.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\proje\\Documents\\GitHub\\Bowser-attack\\bowser\\tesseract_test.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proje/Documents/GitHub/Bowser-attack/bowser/tesseract_test.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# If you have a path to an image file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proje/Documents/GitHub/Bowser-attack/bowser/tesseract_test.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mscreenshots/screenshot_1700386515.png\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/proje/Documents/GitHub/Bowser-attack/bowser/tesseract_test.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(image_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proje/Documents/GitHub/Bowser-attack/bowser/tesseract_test.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Use Tesseract to do OCR on the image\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proje/Documents/GitHub/Bowser-attack/bowser/tesseract_test.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m text \u001b[39m=\u001b[39m pytesseract\u001b[39m.\u001b[39mimage_to_string(image)\n",
      "File \u001b[1;32mc:\\Users\\proje\\anaconda3\\envs\\VerbalEnv2\\lib\\site-packages\\PIL\\Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3240\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3242\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3243\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3244\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3246\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'screenshots/screenshot_1700386515.png'"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# If you have a path to an image file\n",
    "image_path = 'screenshots/screenshot_1700386515.png'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Use Tesseract to do OCR on the image\n",
    "text = pytesseract.image_to_string(image)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_image_with_text('screenshot_1700386515.png', 'screenshot_1700386515a.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def on_drag_start(event):\n",
    "    canvas.coords(\"rectangle\", event.x, event.y, event.x, event.y)\n",
    "\n",
    "def on_drag_motion(event):\n",
    "    canvas.coords(\"rectangle\", canvas.coords(\"rectangle\")[0], canvas.coords(\"rectangle\")[1], event.x, event.y)\n",
    "\n",
    "def on_drag_release(event):\n",
    "    canvas.coords(\"rectangle\", canvas.coords(\"rectangle\")[0], canvas.coords(\"rectangle\")[1], event.x, event.y)\n",
    "    print(\"Rectangle coordinates:\", canvas.coords(\"rectangle\"))\n",
    "    root.destroy()  # Close the window after releasing the mouse\n",
    "\n",
    "root = tk.Tk()\n",
    "root.attributes('-fullscreen', True)  # Fullscreen window\n",
    "root.attributes('-topmost', True)  # Always on top\n",
    "root.attributes('-alpha', 0.3)  # Transparency (1.0: Opaque, <1.0: Transparent)\n",
    "\n",
    "# Remove window decorations\n",
    "root.overrideredirect(True)\n",
    "\n",
    "canvas = tk.Canvas(root, width=root.winfo_screenwidth(), height=root.winfo_screenheight(), bg='white')\n",
    "canvas.pack()\n",
    "\n",
    "\n",
    "# Create a rectangle with a bright red outline\n",
    "rect = canvas.create_rectangle(0, 0, 0, 0, outline='#ff0000', width=5, dash=(4, 2), tag=\"rectangle\")\n",
    "\n",
    "\n",
    "canvas.bind(\"<ButtonPress-1>\", on_drag_start)\n",
    "canvas.bind(\"<B1-Motion>\", on_drag_motion)\n",
    "canvas.bind(\"<ButtonRelease-1>\", on_drag_release)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected area coordinates: (1.0, 0.0, 1535, 864)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def get_window_area():\n",
    "    coordinates = [None]  # List to hold the coordinates\n",
    "\n",
    "    def on_drag_start(event):\n",
    "        canvas.coords(\"rectangle\", event.x, event.y, event.x, event.y)\n",
    "\n",
    "    def on_drag_motion(event):\n",
    "        canvas.coords(\"rectangle\", canvas.coords(\"rectangle\")[0], canvas.coords(\"rectangle\")[1], event.x, event.y)\n",
    "\n",
    "    def on_drag_release(event):\n",
    "        coords = canvas.coords(\"rectangle\")\n",
    "        canvas.coords(\"rectangle\", coords[0], coords[1], event.x, event.y)\n",
    "        coordinates[0] = (coords[0], coords[1], event.x, event.y)  # Store the coordinates\n",
    "        root.destroy()  # Close the window after releasing the mouse\n",
    "\n",
    "    def close(event=None):\n",
    "        root.destroy()  # Function to close the window\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.attributes('-fullscreen', True)\n",
    "    root.attributes('-topmost', True)\n",
    "    root.attributes('-alpha', 0.3)\n",
    "    root.overrideredirect(True)\n",
    "\n",
    "    canvas = tk.Canvas(root, width=root.winfo_screenwidth(), height=root.winfo_screenheight(), bg='white')\n",
    "    canvas.pack()\n",
    "\n",
    "    rect = canvas.create_rectangle(0, 0, 0, 0, outline='#ff0000', width=5, dash=(4, 2), tag=\"rectangle\")\n",
    "\n",
    "    canvas.bind(\"<ButtonPress-1>\", on_drag_start)\n",
    "    canvas.bind(\"<B1-Motion>\", on_drag_motion)\n",
    "    canvas.bind(\"<ButtonRelease-1>\", on_drag_release)\n",
    "\n",
    "    root.bind(\"<Escape>\", close)\n",
    "    root.after(10000, close)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    return coordinates[0]  # Return the stored coordinates\n",
    "\n",
    "# Example usage\n",
    "area = get_window_area()\n",
    "print(\"Selected area coordinates:\", area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\proje\\Documents\\GitHub\\Bowser-attack\\screenshots\\tesseract_test.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/proje/Documents/GitHub/Bowser-attack/screenshots/tesseract_test.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m)\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proje/Documents/GitHub/Bowser-attack/screenshots/tesseract_test.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(x)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "x = (1,2)/2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def highlight_words(image_path):\n",
    "    \"\"\"\n",
    "    Apply OCR to an image and return the image with detected words highlighted in red.\n",
    "\n",
    "    :param image_path: Path to the input image.\n",
    "    :return: Image with detected words highlighted.\n",
    "    \"\"\"\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "    # Load the image\n",
    "    folder = 'c:\\\\Users\\\\proje\\\\Documents\\\\GitHub\\\\Bowser-attack\\\\bowser\\\\base_segment\\\\test_screenshots\\\\'\n",
    "    image = cv2.imread(folder + 'Screenshot 2023-11-21 134221.png')\n",
    "\n",
    "    # Convert to RGB (as Tesseract expects images in this format)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run Tesseract OCR\n",
    "    data = pytesseract.image_to_data(rgb_image, config='--psm 3', output_type=pytesseract.Output.DICT)\n",
    "\n",
    "    # Iterate through OCR result and highlight words\n",
    "    n_boxes = len(data['level'])\n",
    "    for i in range(n_boxes):\n",
    "        if int(data['conf'][i]) > 0:  # Confidence threshold to filter weak detections\n",
    "            (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "            image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red rectangle\n",
    "            text = data['text'][i]\n",
    "            cv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Example usage\n",
    "highlighted_image = highlight_words('path_to_your_image.jpg')\n",
    "cv2.imshow('Highlighted Image', highlighted_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Collecting numpy>=1.21.2 (from opencv-python)\n",
      "  Using cached numpy-1.26.2-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.2\n",
      "    Uninstalling numpy-1.26.2:\n",
      "      Successfully uninstalled numpy-1.26.2\n",
      "Successfully installed numpy-1.26.2 opencv-python-4.8.1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\proje\\anaconda3\\envs\\verbalenv2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\proje\\anaconda3\\envs\\verbalenv2\\lib\\site-packages)\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\proje\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "label-studio 1.9.2.post0 requires numpy==1.24.3, but you have numpy 1.26.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall --user opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "def highlight_words_easyocr(image_path):\n",
    "    \"\"\"\n",
    "    Apply OCR using EasyOCR to an image and return the image with detected words highlighted in red and the text printed on top.\n",
    "\n",
    "    :param image_path: Path to the input image.\n",
    "    :return: Image with detected words highlighted.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a reader to detect text\n",
    "    reader = easyocr.Reader(['en'])  # 'en' denotes English language; you can add more languages if needed\n",
    "\n",
    "    # Load the image\n",
    "    folder = 'c:\\\\Users\\\\proje\\\\Documents\\\\GitHub\\\\Bowser-attack\\\\bowser\\\\base_segment\\\\test_screenshots\\\\'\n",
    "    image = cv2.imread(folder + 'Screenshot 2023-11-21 134221.png')\n",
    "\n",
    "    # Perform OCR\n",
    "    results = reader.readtext(image, text_threshold=0.5)\n",
    "\n",
    "    # Iterate through the results and highlight words\n",
    "    for (bbox, text, prob) in results:\n",
    "        # Unpack the bounding box\n",
    "        (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "        top_left = (int(top_left[0]), int(top_left[1]))\n",
    "        bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "\n",
    "        # Draw the bounding box\n",
    "        image = cv2.rectangle(image, top_left, bottom_right, (0, 0, 255), 2)\n",
    "\n",
    "        # Put the OCR text\n",
    "        text_loc = (top_left[0], top_left[1] - 10)  # Slightly above the top left of the bbox\n",
    "        image = cv2.putText(image, text, text_loc, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        image = cv2.putText(image, text, text_loc, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Example usage\n",
    "highlighted_image = highlight_words_easyocr('path_to_your_image.jpg')\n",
    "cv2.imshow('Highlighted Image', highlighted_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VerbalEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
